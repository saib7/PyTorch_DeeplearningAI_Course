{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f155d46a",
   "metadata": {},
   "source": [
    "# Programming Assignment: Building a Robust Data Pipeline\n",
    "\n",
    "Welcome to the assignment for Data Management in PyTorch.\n",
    "\n",
    "In earlier examples, you've worked with clean, pre-packaged datasets. In reality, data is rarely that simple. In computer vision, images often come in different sizes and formats and must be preprocessed before a model can learn from them. Manually handling this for thousands of images would be both tedious and error-prone.\n",
    "\n",
    "In this assignment, youâ€™ll work with the [Plants Classification](https://www.kaggle.com/datasets/marquis03/plants-classification) dataset, which contains 30,000 `.jpg` images across 30 plant species such as aloe vera, banana, spinach, and watermelon. Like many real-world datasets, the images vary in size and quality and are organized into folders by class. For this exercise, youâ€™ll use a subset of 3,000 images.\n",
    "\n",
    "This is where a data pipeline comes in. Youâ€™ll get hands-on experience building a custom dataset, applying the necessary transformations, and loading your data in batches. These are the essential first steps before training a deep learning model.\n",
    "\n",
    "**What You will do in this Assignment**\n",
    "\n",
    "* Access and explore the structure of an image dataset.\n",
    "* Build a custom `Dataset` class to load your images and labels on demand.\n",
    "* Define a series of `transformations`, including resizing, tensor conversion, and `normalization`, to preprocess the data.\n",
    "* Define augmentation transforms to enhance the training dataset.\n",
    "* Split the dataset into training, validation, and test sets applying the appropriate transforms to each and creating `DataLoader` instances for efficient batching.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bfc0c1",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "* To submit your notebook for grading, first save it by clicking the ðŸ’¾ icon on the top left of the page and then click on the `Submit assignment` button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41390f",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Imports](#imports)\n",
    "- [1 - Data Access](#1---data-access)\n",
    "    - [1.1 - Exploring the Dataset](#11---exploring-the-dataset)\n",
    "    - [1.2 - Creating a Custom Dataset Class](#12---creating-a-custom-dataset-class)\n",
    "        - **[Exercise 1 - PlantsDataset](#exercise-1---plantsdataset)**\n",
    "    - [1.3 - Overview of the images in the dataset](#13---overview-of-the-images-in-the-dataset)\n",
    "- [2 - Transformations](#2---transformations)\n",
    "    - [2.1 - Computing Mean and Standard Deviation](#21---computing-mean-and-standard-deviation)\n",
    "    - [2.2 - Defining Transformations](#22---defining-transformations)\n",
    "        - **[Exercise 2 - get_transformations](#exercise-2---get_transformations)**\n",
    "- [3 - Data Loading](#3---data-loading)\n",
    "    - **[Exercise 3 - get_data_loaders](#exercise-3---get_data_loaders)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d6b12",
   "metadata": {},
   "source": [
    "<a name='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MJUe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vblA",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import helper_utils\n",
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ba742",
   "metadata": {},
   "source": [
    "<a name='1---data-access'></a>\n",
    "## 1 - Data Access "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361e05b",
   "metadata": {},
   "source": [
    "<a name='11---exploring-the-dataset'></a>\n",
    "### 1.1 - Exploring the Dataset\n",
    "\n",
    "As youâ€™ve already learned, the first step when working with any new dataset is to explore it. This involves understanding its structure, the types of data it contains, and identifying any potential issues such as missing values or outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e431af2",
   "metadata": {},
   "source": [
    "In this step, youâ€™ll use the `print_data_folder_structure` function from `helper_utils` to print the dataset's folder layout. \n",
    "This will help you see how the files and directories are organized, a crucial step before you start loading and preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "PKri",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plants_dataset\n",
      "Exception Occurred! Failed to Generate Tree:: FileNotFoundError: [WinError 3] The system cannot find the path specified: 'plants_dataset'\n"
     ]
    }
   ],
   "source": [
    "path_dataset = './plants_dataset'\n",
    "\n",
    "helper_utils.print_data_folder_structure(path_dataset, max_depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0b539",
   "metadata": {},
   "source": [
    "You now have an initial understanding of the dataset structure:\n",
    "- `df_labels.csv`,\n",
    "- `classname.txt`,\n",
    "- One folder per class, each containing the images for that class (all in `.jpg` format).\n",
    "\n",
    "This information will be useful when you design your custom Dataset class later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1792269",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './plants_dataset/df_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print the content of `df_labels.csv`\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_labels = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_dataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/df_labels.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_labels.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TECH MOON\\Desktop\\Home_Practice\\Pytorch_DLAI\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TECH MOON\\Desktop\\Home_Practice\\Pytorch_DLAI\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TECH MOON\\Desktop\\Home_Practice\\Pytorch_DLAI\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TECH MOON\\Desktop\\Home_Practice\\Pytorch_DLAI\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TECH MOON\\Desktop\\Home_Practice\\Pytorch_DLAI\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './plants_dataset/df_labels.csv'"
     ]
    }
   ],
   "source": [
    "# print the content of `df_labels.csv`\n",
    "df_labels = pd.read_csv(f'{path_dataset}/df_labels.csv')\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e732fa1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# print the content of `class_names.txt`\n",
    "with open(f'{path_dataset}/classname.txt', 'r') as f:\n",
    "    class_names = f.read().splitlines()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b48230",
   "metadata": {},
   "source": [
    "Youâ€™ve verified that `df_labels.csv` contains the labels for each image along with their corresponding file names, and that `classname.txt` contains the names of all the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf351be",
   "metadata": {},
   "source": [
    "<a name='12---creating-a-custom-dataset-class'></a>\n",
    "### 1.2 - Creating a Custom Dataset Class\n",
    "\n",
    "It is now time to create a custom dataset class to handle the plant images dataset. \n",
    "This class will inherit from `torch.utils.data.Dataset` and will be responsible for loading and preprocessing the images along with their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20384fa",
   "metadata": {},
   "source": [
    "<a name='exercise-1---plantsdataset'></a>\n",
    "#### **Exercise 1 - `PlantsDataset`**\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Your task is to complete the implementation of the custom PyTorch Dataset class `PlantsDataset`. \n",
    "You need to implement the missing code in multiple sections within the class:\n",
    "\n",
    "* **Complete the `__init__` method**:\n",
    "    * Load labels from the DataFrame using the already defined `load_labels` method on the `.df_info` attribute.\n",
    "    * Create a mapping from label integers to class names using the already defined `read_classname` method.\n",
    "\n",
    "* **Complete the `__len__` method**:\n",
    "    * Return the total number of samples in the dataset by extracting the length of the `.labels` attribute.\n",
    "\n",
    "* **Complete the `__getitem__` method**:\n",
    "    * Retrieve the image at the specified index using the existing `retrieve_image` method.\n",
    "    * Apply transformations to the image if they are specified.\n",
    "    * Get the corresponding label from the `.labels` attribute.\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "If you need a little help, here's a more detailed guide for each method:\n",
    "\n",
    "**For the `__init__` method:**\n",
    "* For `self.labels`: Call `self.load_labels()` to extract labels from the `self.df_info` DataFrame.\n",
    "\n",
    "**For the `__len__` method:**\n",
    "* Use the built-in `len()` function on `self.labels`.\n",
    "\n",
    "**For the `__getitem__` method:**\n",
    "* Use `self.retrieve_image(idx)` to get the image at the specified index.\n",
    "* If `self.transform` is not None, apply it to the image using `self.transform(image)`.\n",
    "* Get the label from `self.labels[idx]`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f33e29",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: PlantsDataset\n",
    "class PlantsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ExDataset is a custom PyTorch Dataset for loading images and their corresponding labels from a specified directory and CSV file.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root directory containing the dataset files, including 'classname.txt'.\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (str): Path to the root directory of the dataset.\n",
    "        transform (callable): Transformations to apply to the images.\n",
    "        df_info (pd.DataFrame): DataFrame containing image file names and category labels.\n",
    "        labels (list): List of integer labels for each image.\n",
    "        class_names (list): List of class names corresponding to label indices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform= None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset object.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): Path to the root directory containing the dataset.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize path to root directory and transformations\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read the CSV file (with images path and category labels)\n",
    "        self.df_info = self.read_df()\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Load labels from the DataFrame using the `load_labels` method\n",
    "        self.labels = self.load_labels(self.df_info)    \n",
    "\n",
    "        # Create a mapping from label integers to class names using the `read_classname` method\n",
    "        self.class_names = self.read_classname()\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def read_df(self):\n",
    "        \"\"\"\n",
    "        Reads a CSV file from the specified path and returns it as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        path_csv = self.root_dir + \"/df_labels.csv\"\n",
    "        df = pd.read_csv(path_csv)\n",
    "        return df\n",
    "\n",
    "    def read_classname(self):\n",
    "        \"\"\"\n",
    "        Reads class names from a file named 'classname.txt' located in the root directory.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of class names, each as a string, read from the file.\n",
    "        \"\"\"\n",
    "        path_txt = self.root_dir + \"/classname.txt\"\n",
    "        with open(path_txt, \"r\") as f:\n",
    "            class_names = f.read().splitlines()\n",
    "        return class_names\n",
    "\n",
    "    def load_labels(self, df):\n",
    "        \"\"\"\n",
    "        Extracts label integers from a DataFrame and returns them as a list.\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            label_int = row[\"category\"]\n",
    "            labels.append(label_int)\n",
    "        return labels\n",
    "\n",
    "    def get_label_description(self, label: int):\n",
    "        \"\"\"\n",
    "        Returns the description of a class label.\n",
    "        \"\"\"\n",
    "        description = self.class_names[label]\n",
    "        return description\n",
    "\n",
    "    def retrieve_image(self, idx: int):\n",
    "        \"\"\"\n",
    "        Retrieves and returns from the folder the PIL image at the specified index.\n",
    "        It converts the image to RGB mode.\n",
    "        \"\"\"\n",
    "        img_path = self.root_dir + \"/\" + self.df_info.iloc[idx][\"image:FILE\"]\n",
    "        with Image.open(img_path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "        return image\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        # Return the total number of samples from the `.labels` attribute\n",
    "        length = len(self.labels)\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the image and its corresponding label at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple (image, label) where:\n",
    "                - image: The image at the given index, possibly transformed if a transform is specified.\n",
    "                - label: The label corresponding to the image.\n",
    "        \"\"\"\n",
    "        # Retrieve the image using the `retrieve_image` method\n",
    "        image = self.retrieve_image(idx)\n",
    "\n",
    "        # Apply the specified transformations to the image, if any\n",
    "        # The None of the if condition is not part of the exercise, leave it as is\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Retrieve the label from the `labels` attribute\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Return the image and label\n",
    "        return image, label  \n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0c0d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plants_dataset = PlantsDataset(root_dir=path_dataset, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af228ec1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# print the length of the dataset\n",
    "print(f'Length of the dataset: {len(plants_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee37f9e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Look at a sample to check it's working correctly\n",
    "sel_idx = 10\n",
    "img, label = plants_dataset[sel_idx]\n",
    "\n",
    "# Visualize the image\n",
    "helper_utils.plot_img(img)\n",
    "\n",
    "# Print its description\n",
    "print(f'Description: {plants_dataset.get_label_description(label)}')\n",
    "\n",
    "# Print its shape\n",
    "print(f'Image shape: {img.size}')  # PIL image size is (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e5645",
   "metadata": {},
   "source": [
    "##### **Expected Output**\n",
    "```\n",
    "Description: aloevera\n",
    "Image shape: (269, 187)\n",
    "```\n",
    "\n",
    "![exp_out_1.png](exp_out_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ee671",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_1(PlantsDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b167e8",
   "metadata": {},
   "source": [
    "<a name='13---overview-of-the-images-in-the-dataset'></a>\n",
    "### 1.3 - Overview of the images in the dataset\n",
    "\n",
    "The images are now accessible through the custom dataset class you implemented in the previous exercise. However, they havenâ€™t been preprocessed yet, a necessary step before feeding them into a neural network.\n",
    "\n",
    "In this step, youâ€™ll explore the dataset using the `visual_exploration` function from `helper_utils`.\n",
    "This function displays a few sample images along with their labels, allowing you to visually inspect the data and get a sense of its main characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "helper_utils.visual_exploration(plants_dataset, num_rows=2, num_cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd8c15",
   "metadata": {},
   "source": [
    "From the visual exploration, you can see that the images in the dataset vary in size, color, and background.\n",
    "This kind of variability is common in real-world datasets and underscores the importance of preprocessing steps such as resizing, normalization, and data augmentation to help the model generalize effectively across different types of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "<a name='2---transformations'></a>\n",
    "## 2 - Transformations\n",
    "\n",
    "Before feeding images into a neural network, you need to preprocess them using a series of transformations.\n",
    "These steps include resizing the images to a consistent size, converting them into tensors, and normalizing their pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0a120",
   "metadata": {},
   "source": [
    "<a name='21---computing-mean-and-standard-deviation'></a>\n",
    "### 2.1 - Computing Mean and Standard Deviation\n",
    "\n",
    "Below is an auxiliary function, `get_mean_std`, that computes the mean and standard deviation of the dataset. Both values are needed for the normalization transformation later on.\n",
    "\n",
    "The normalization transform will be applied after resizing and converting the images to tensors.\n",
    "Since these two transformations change the pixel value distribution, itâ€™s important to compute the mean and standard deviation after they are applied.\n",
    "\n",
    "In `get_mean_std` you will:\n",
    "\n",
    "* **Preprocessing Setup**: Create a transform pipeline that resizes images to 128Ã—128 and converts PIL images to tensors.\n",
    "* **Per-Image Processing**: Loop through each image in the dataset, applying the transforms and computing the mean and standard deviation across spatial dimensions (height/width) using `dim=[1, 2]`\n",
    "* **Statistics Collection**: Store each imageâ€™s channel-wise statistics in separate lists (`means` and `stds`)\n",
    "* **Global Calculation**: Stack all per-image statistics into tensors and average across all images to get dataset-wide channel statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43ff8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def get_mean_std(dataset: Dataset):\n",
    "    # Define deterministic preprocessing (resize) + ToTensor\n",
    "    preprocess = transforms.Compose(\n",
    "        [transforms.Resize((128, 128)), transforms.ToTensor()]\n",
    "    )\n",
    "\n",
    "    # Lists to store per-image statistics\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for img, _ in dataset:  # _ is the label\n",
    "        # img is a PIL Image\n",
    "        img_tensor = preprocess(img)\n",
    "        means.append(img_tensor.mean(dim=[1, 2]))\n",
    "        stds.append(img_tensor.std(dim=[1, 2]))\n",
    "\n",
    "    # Stack and compute overall mean/std\n",
    "    mean = torch.stack(means).mean(dim=0)\n",
    "    std = torch.stack(stds).mean(dim=0)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define the transformations to make to the images\n",
    "mean, std = get_mean_std(plants_dataset)\n",
    "\n",
    "print(f\"Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1520d",
   "metadata": {},
   "source": [
    "<a name='22---defining-transformations'></a>\n",
    "### 2.2 - Defining Transformations\n",
    "\n",
    "Having computed the mean and standard deviation of the dataset, you can now define the transformations to apply to the images.\n",
    "Youâ€™ll create two sets of transformations: one for the training set, which includes data augmentation, and another for the validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e292209",
   "metadata": {},
   "source": [
    "<a name='exercise-2---get_transformations'></a>\n",
    "#### **Exercise 2 - `get_transformations`**\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Your task is to implement the missing code in the `get_transformations` function to create two image transformation pipelines for PyTorch. \n",
    "\n",
    "You will implement the following sections:\n",
    "\n",
    "* **Define `main_tfs`**:\n",
    "    * Create a `Resize` transform to resize images to 128x128 pixels.\n",
    "    * Create a `ToTensor` transform to convert PIL images to PyTorch tensors.\n",
    "    * Create a `Normalize` transform using the provided mean and standard deviation values.\n",
    "\n",
    "* **Define `augmentation_tfs`**:\n",
    "    * Create a `RandomVerticalFlip` transform with 50% probability.\n",
    "    * Create a `RandomRotation` transform that rotates images by Â±15 degrees.\n",
    "\n",
    "* **Compose Transform Pipelines**:\n",
    "    * Create `main_transform` by combining the main transforms into a single pipeline using `transforms.Compose`.\n",
    "    * Create `transform_with_augmentation` by combining both augmentation and main transforms into an augmented pipeline.\n",
    "    The augmentation transforms should be applied before the main transforms.\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "If you need a little help, here's a more detailed guide for each section:\n",
    "\n",
    "**For `main_tfs`:**\n",
    "* For `Resize`: Use `transforms.Resize((128, 128))` to resize all images to 128x128 pixels.\n",
    "* For `ToTensor`: Use `transforms.ToTensor()` to convert PIL images to PyTorch tensors.\n",
    "* For `Normalize`: Use `transforms.Normalize(mean=mean, std=std)` with the provided mean and std parameters.\n",
    "\n",
    "\n",
    "**For `augmentation_tfs`:**\n",
    "* For `RandomVerticalFlip`: Use `transforms.RandomVerticalFlip(p=0.5)` to flip images vertically with 50% probability.\n",
    "* For `RandomRotation`: Use `transforms.RandomRotation(degrees=15)` to rotate images randomly within Â±15 degrees.\n",
    "\n",
    "\n",
    "**For composing transforms:**\n",
    "* For `main_transform`: Use `transforms.Compose(main_tfs)` to combine the main transforms list.\n",
    "* For `transform_with_augmentation`: Use `transforms.Compose(augmentation_tfs + main_tfs)` to combine both lists.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbe636",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION : get_transformations\n",
    "def get_transformations(mean, std):\n",
    "    \"\"\"\n",
    "    Returns two sets of image transformation pipelines: one with basic preprocessing and another with additional data augmentation.\n",
    "\n",
    "    Args:\n",
    "        mean: Sequence of mean values for normalization.\n",
    "        std: Sequence of standard deviation values for normalization.\n",
    "\n",
    "    Returns:\n",
    "        main_transform: Transformation pipeline with resizing, tensor conversion, and normalization.\n",
    "        transform_with_augmentation: Transformation pipeline including random vertical flip, random rotation, resizing, tensor conversion, and normalization.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    main_tfs = [  \n",
    "        # Resize images to 128x128 pixels\n",
    "        transforms.Resize((128, 128)),\n",
    "        # Convert images to PyTorch tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize images using the provided mean and std\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ]  \n",
    "\n",
    "    augmentation_tfs = [  \n",
    "        # Randomly flip the image vertically\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        # Randomly rotate the image by Â±15 degrees\n",
    "        transforms.RandomRotation(degrees=15)\n",
    "    ]  \n",
    "\n",
    "    # Compose the main transformations into a single pipeline\n",
    "    main_transform = transforms.Compose(main_tfs)\n",
    "\n",
    "    transform_with_augmentation = transforms.Compose(augmentation_tfs + main_tfs)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return main_transform, transform_with_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Get the transformations\n",
    "main_transform, transform_with_augmentation = get_transformations(mean, std)\n",
    "\n",
    "# Print the transformations to verify\n",
    "print(main_transform)\n",
    "print(transform_with_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacc84d",
   "metadata": {},
   "source": [
    "##### **Expected Output**\n",
    "\n",
    "```\n",
    "Compose(\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2119, 0.2155, 0.2567]))\n",
    ")\n",
    "Compose(\n",
    "    RandomVerticalFlip(p=0.5)\n",
    "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2119, 0.2155, 0.2567]))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3fccd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_2(get_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5e749",
   "metadata": {},
   "source": [
    "You can verify your transformations by applying them to a sample image from the dataset and inspecting the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585ba6a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Check main_transform on a sample image\n",
    "img_transformed = main_transform(img)\n",
    "print(f\"Transformed Image shape: {img_transformed.shape}\")\n",
    "\n",
    "\n",
    "# get denormalization function\n",
    "denormalize = helper_utils.Denormalize(mean, std)\n",
    "# visualize the augmented image\n",
    "img_augmented = transform_with_augmentation(img)\n",
    "helper_utils.plot_img(denormalize(img_augmented), info=f\"Augmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993bb3e2",
   "metadata": {},
   "source": [
    "<a name='3---data-loading'></a>\n",
    "## 3 - Data Loading\n",
    "\n",
    "With your custom dataset class and transformations defined, you can now create data loaders to efficiently load and batch data for training and evaluation. This is the final step before you would train a neural network on this dataset.\n",
    "\n",
    "As in the previous lab, after using `random_split` to divide the dataset into training, validation, and test sets, you need to ensure that each subset uses the appropriate transformations. \n",
    "One way to change the transformations of each subset is by wrapping the subsets in new instances of the custom dataset class `SubsetWithTransform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fce01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class SubsetWithTransform(Dataset):\n",
    "    \"\"\"A subset of a dataset with a specific transform applied.\"\"\"\n",
    "\n",
    "    def __init__(self, subset: Subset, transform=None):\n",
    "        # subset should be a subset WITHOUT transform\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95714fa",
   "metadata": {},
   "source": [
    "<a name='exercise-3---get_data_loaders'></a>\n",
    "#### **Exercise 3 - `get_data_loaders`**\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Your task is to complete the implementation of the `get_dataloaders` function to split a dataset and create PyTorch DataLoaders for training, validation, and testing. \n",
    "You need to implement the missing code in three main sections:\n",
    "\n",
    "* **Split the Dataset**:\n",
    "    * Use `random_split` to divide the dataset into training, validation, and test sets based on the calculated sizes.\n",
    "\n",
    "* **Apply Transforms to Each Split**:\n",
    "    * Wrap each dataset split with `SubsetWithTransform` to apply appropriate transforms.\n",
    "    * Use `augmentation_transform` for the training set to include data augmentation.\n",
    "    * Use `main_transform` for both validation and test sets (no augmentation needed).\n",
    "\n",
    "* **Create DataLoaders**:\n",
    "    * Create `DataLoader` objects for each dataset split with the specified batch size.\n",
    "    * Enable shuffling for the training loader to randomize batch order.\n",
    "    * Disable shuffling for validation and test loaders to maintain consistent evaluation.\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "If you need a little help, here's a more detailed guide for each section:\n",
    "\n",
    "**For splitting the dataset:**\n",
    "* Use `random_split(dataset, [train_size, val_size, test_size])` to split the dataset.\n",
    "\n",
    "**For applying transforms:**\n",
    "* Use `SubsetWithTransform(dataset_split, transform=transform_to_apply)` for each split.\n",
    "\n",
    "**For creating DataLoaders:**\n",
    "* Use `DataLoader(dataset=dataset_split, batch_size=batch_size, shuffle=shuffle_setting)`.\n",
    "* For training loader: set `shuffle=True` to randomize the order of batches.\n",
    "* For validation and test loaders: set `shuffle=False` to maintain consistent order for evaluation.\n",
    "* All loaders should use the same `batch_size` parameter.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION : get_dataloaders\n",
    "def get_dataloaders(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    val_fraction,\n",
    "    test_fraction,\n",
    "    main_transform,\n",
    "    augmentation_transform,\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits a dataset into training, validation, and test sets, applies specified transforms to each split,\n",
    "    and returns corresponding DataLoader objects.\n",
    "\n",
    "    Args:\n",
    "        dataset: The full dataset to be split.\n",
    "        batch_size: Number of samples per batch to load.\n",
    "        val_fraction: Fraction of the dataset to use for validation.\n",
    "        test_fraction: Fraction of the dataset to use for testing.\n",
    "        main_transform: Transform to apply to validation and test splits.\n",
    "        augmentation_transform: Transform to apply to the training split.\n",
    "\n",
    "    Returns:\n",
    "        train_loader: DataLoader for the training set with augmentation transforms.\n",
    "        val_loader: DataLoader for the validation set with main transforms.\n",
    "        test_loader: DataLoader for the test set with main transforms.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the sizes of each split\n",
    "    total_size = len(dataset)\n",
    "    val_size = int(total_size * val_fraction)\n",
    "    test_size = int(total_size * test_fraction)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset,\n",
    "        [train_size, val_size, test_size]\n",
    "    )  \n",
    "\n",
    "    # Create dataset with the corresponding transforms for each split\n",
    "    train_dataset = SubsetWithTransform(train_dataset, augmentation_transform)\n",
    "    val_dataset = SubsetWithTransform(val_dataset, main_transform)\n",
    "    test_dataset =  SubsetWithTransform(test_dataset, main_transform)\n",
    "\n",
    "    # Create DataLoaders for each split\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c54af4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    dataset=plants_dataset,\n",
    "    batch_size=32,\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.2,\n",
    "    main_transform=main_transform,\n",
    "    augmentation_transform=transform_with_augmentation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632faba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('=== Train Loader ===')\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "train_dataset = train_loader.dataset\n",
    "print(f\"Number of samples in train_dataset: {len(train_dataset)}\")\n",
    "print(f\"Transforms applied to train_dataset: {train_dataset.transform}\")\n",
    "print(f\"train_dataset type: {type(train_dataset)}\")\n",
    "\n",
    "print('\\n=== Test Loader ===')\n",
    "print(f\"Number of batches in test_loader: {len(test_loader)}\")\n",
    "test_dataset = test_loader.dataset\n",
    "print(f\"Number of samples in test_dataset: {len(test_dataset)}\")\n",
    "print(f\"Transforms applied to test_dataset: {test_dataset.transform}\")\n",
    "print(f\"test_dataset type: {type(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685faf25",
   "metadata": {},
   "source": [
    "##### **Expected Output**\n",
    "\n",
    "```\n",
    "=== Train Loader ===\n",
    "Number of batches in train_loader: 61\n",
    "Number of samples in train_dataset: 1950\n",
    "Transforms applied to train_dataset: Compose(\n",
    "    RandomVerticalFlip(p=0.5)\n",
    "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2119, 0.2155, 0.2567]))\n",
    ")\n",
    "train_dataset type: <class 'helper_utils.SubsetWithTransform'>\n",
    "\n",
    "=== Test Loader ===\n",
    "Number of batches in test_loader: 19\n",
    "Number of samples in test_dataset: 600\n",
    "Transforms applied to test_dataset: Compose(\n",
    "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0.6659, 0.6203, 0.4784]), std=tensor([0.2119, 0.2155, 0.2567]))\n",
    ")\n",
    "test_dataset type: <class 'helper_utils.SubsetWithTransform'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e450",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_3(get_dataloaders, plants_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae937106",
   "metadata": {},
   "source": [
    "---\n",
    "# Submission Note\n",
    "\n",
    "Congratulations! You've completed the final graded exercise of this assignment.\n",
    "\n",
    "If you've successfully passed all the unit tests above, you've completed the core requirements of this assignment. Feel free to [submit](#submission) your work now. The grading process runs in the background, so it will not disrupt your progress and you can continue on with the rest of the material.\n",
    "\n",
    "**ðŸš¨ IMPORTANT NOTE** If you have passed all tests within the notebook, but the autograder shows a system error after you submit your work:\n",
    "\n",
    "<div style=\"background-color: #1C1C1E; border: 1px solid #444444; color: #FFFFFF; padding: 15px; border-radius: 5px;\">\n",
    "    <p><strong>Grader Error: Grader feedback not found</strong></p>\n",
    "    <p>Autograder failed to produce the feedback...</p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "This is typically a temporary system glitch. The most common solution is to resubmit your assignment, as this often resolves the problem. Occasionally, it may be necessary to resubmit more than once. \n",
    ">\n",
    "If the error persists, please reach out for support in the [DeepLearning.AI Community Forum](https://community.deeplearning.ai/c/course-q-a/pytorch-for-developers/pytorch-fundamentals/560).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f1953",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have now built an end-to-end data pipeline in PyTorch. \n",
    "\n",
    "In this lab, you learned how to construct a complete pipeline to handle a real-world image dataset. You moved beyond basic data loading to explore the core components that make up a PyTorch data pipeline.\n",
    "\n",
    "You created a custom **`Dataset`** for **data access**, defined a sequence of **transformations** such as resizing, normalization, and data augmentation to improve training robustness, split the dataset into training, validation, and test sets, and used **`DataLoader`** for efficient for efficient batching and iteration.\n",
    "\n",
    "With these fundamental componentsâ€”`Dataset`, `Transforms`, and `DataLoader`â€”you now have a clean, efficient, and reusable workflow for preparing any image dataset for training a neural network. "
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
